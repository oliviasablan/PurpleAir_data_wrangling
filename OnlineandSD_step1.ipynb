{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2cf695b",
   "metadata": {},
   "source": [
    "## OnlineandSD_step1\n",
    "### Author: Olivia Sablan\n",
    "The following code is used to read in files from the PurpleAir Data Download Tool and files removed from the PurpleAir SD card and compile the data. \n",
    "\n",
    "Last updated: May 19, 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a4f6678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "import pathlib\n",
    "from datetime import datetime\n",
    "pd.options.mode.copy_on_write = True\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca9d2a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This reads the google spreadsheet with all the field sensor info as a csv\n",
    "google = pd.read_csv('https://docs.google.com/spreadsheets/')\n",
    "# Drop the sensors that haven't been registered and have no ID to pull data from and make it an integer\n",
    "google = google.dropna(subset = ['Sensor ID to Pull'])\n",
    "google['Sensor ID to Pull'] = google['Sensor ID to Pull'].astype(int)\n",
    "\n",
    "# To loop through the sensor IDs, I make lists of the ID used to pull them as an integer and a string\n",
    "senslist=np.array(google['Sensor ID to Pull'][:],dtype='int')\n",
    "strsenslist= [str(i) for i in senslist]\n",
    "\n",
    "# Because some sensors were put in multiple locations (but have the same ID to pull) I make another list \n",
    "# for the 'Sensor ID for User' to save the data separately when a sensor was used twice\n",
    "senslist2=np.array(google['Sensor ID for User'][:],dtype='int')\n",
    "strsenslist2= [str(i) for i in senslist2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5eafb33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the directory where I put the data I downloaded from the PurpleAir Data Download Tool\n",
    "# note: this is only online data for the sensors that were on WiFi and could report their data to PurpleAir storage\n",
    "dir_list = os.listdir('../data/datadownloadtool/')\n",
    "# We don't need \"DS.store\" to be in the list because it doesn't have data in it\n",
    "dir_list = [file for file in dir_list if file != '.DS_Store']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6da34aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I pulled data every month, and the data download tool stores the .csv by the dates of the data \n",
    "# I store the end of the names of the csv's here so I can loop through each csv later\n",
    "endofstring = []\n",
    "for i in range(len(dir_list)):\n",
    "    endofstring.append(os.listdir('../data/datadownloadtool/' + dir_list[i])[1][6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7c7bac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as above, but I want to store the exact date I pulled the data, which is only characters 19:29\n",
    "dates_pulled = []\n",
    "for i in range(len(dir_list)):\n",
    "    dates_pulled.append(dir_list[i][19:29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c798e384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need all the lists to iterate through in the right order\n",
    "dates_pulled.sort(key=lambda date: datetime.strptime(date, '%m-%d-%Y')) \n",
    "endofstring.sort()\n",
    "dir_list.sort(key=lambda x: datetime.strptime(x.split()[-1], '%m-%d-%Y'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80a48bf",
   "metadata": {},
   "source": [
    "### Compiling data from the PurpleAir Data Download Tool:\n",
    "Note: this is only data that was stored on the PurpleAir servers from sensors that were on WiFi. This may not include all of the data collected by the sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0962a8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "online_df = pd.DataFrame()\n",
    "\n",
    "# start looping through each data file that contains all IDs\n",
    "for ii in range(len(dir_list)):\n",
    "    for i in range(len(strsenslist)):\n",
    "        file = pathlib.Path('../data/datadownloadtool/' + dir_list[ii] + '/' + strsenslist[i] + endofstring[ii])\n",
    "        if file.exists():  # Only continue if the sensor file exists\n",
    "            df = pd.read_csv(file)\n",
    "            if len(df) > 0:  # Only continue if there's data in the sensor file\n",
    "                df.rename(columns={'time_stamp': 'created_at'}, inplace=True)  # Rename to match previous data\n",
    "                df['created_at'] = pd.to_datetime(df['created_at'], format=\"%Y-%m-%dT%H:%M:%Sz\")  # Convert to datetime\n",
    "                sensor_instances = google[google['Sensor ID to Pull'] == senslist[i]]\n",
    "                if len(sensor_instances) > 1:\n",
    "                    start1 = google['Start'][google['Sensor ID to Pull'] == senslist[i]].iloc[0]\n",
    "                    end1 = google['Stop'][google['Sensor ID to Pull'] == senslist[i]].iloc[0]\n",
    "                    start2 = google['Start'][google['Sensor ID to Pull'] == senslist[i]].iloc[1]\n",
    "                    # First time sensor was used\n",
    "                    sensor1 = df[(df['created_at'].dt.strftime('%Y/%m/%d') >= start1) & (df['created_at'].dt.strftime('%Y/%m/%d') <= end1)]\n",
    "                    ten1 = sensor1.groupby(pd.Grouper(key=\"created_at\", freq=\"10min\")).mean(numeric_only=True).reset_index()\n",
    "                    ten1['ID'] = strsenslist[i]\n",
    "                    # Second time sensor was used\n",
    "                    sensor2 = df[(df['created_at'].dt.strftime('%Y/%m/%d') >= start2) ]\n",
    "                    ten2 = sensor2.groupby(pd.Grouper(key=\"created_at\", freq=\"10min\")).mean(numeric_only=True).reset_index()\n",
    "                    ten2['ID'] = strsenslist[i] + '2'\n",
    "                    online_df = pd.concat([online_df, ten1])\n",
    "                    online_df = pd.concat([online_df, ten2])\n",
    "                else:\n",
    "                    start1 = google['Start'][google['Sensor ID to Pull'] == senslist[i]].iloc[0]\n",
    "                    end1 = google['Stop'][google['Sensor ID to Pull'] == senslist[i]].iloc[0]\n",
    "\n",
    "                    if pd.isna(end1):\n",
    "                        df = df[df['created_at'].dt.strftime('%Y/%m/%d') >= start1]\n",
    "                        ten3 = df.groupby(pd.Grouper(key=\"created_at\", freq=\"10min\")).mean(numeric_only = True).reset_index()\n",
    "                        ten3['ID'] = strsenslist[i]\n",
    "                        online_df = pd.concat([online_df, ten3])\n",
    "                    else:\n",
    "                        df = df[(df['created_at'].dt.strftime('%Y/%m/%d') >= start1) & (df['created_at'].dt.strftime('%Y/%m/%d') <= end1)]\n",
    "                        ten4 = df.groupby(pd.Grouper(key=\"created_at\", freq=\"10min\")).mean(numeric_only = True).reset_index()\n",
    "                        ten4['ID'] = strsenslist[i]\n",
    "                        online_df = pd.concat([online_df, ten4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16daf466",
   "metadata": {},
   "source": [
    "### Compiling data from the PurpleAir SD cards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa011e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SD_df = pd.DataFrame()\n",
    "for i in range(len(senslist)):\n",
    "    inputfiles = glob.glob('../data/SD_card/'+ strsenslist[i] +'/*.csv') # Files from the SD cards are put in one directory for each sensor\n",
    "    if (len(inputfiles) > 0): # only continue if there is a datafile for the particular sensor\n",
    "        df_from_each_file = (pd.read_csv(f) for f in inputfiles)\n",
    "        df = pd.concat(df_from_each_file,sort=False)\n",
    "        df = df[['UTCDateTime', 'current_humidity', 'current_temp_f', 'pm2_5_cf_1', 'pm2_5_cf_1_b']] #keep only necessary coljumns\n",
    "        df = df.rename(columns = {'UTCDateTime': 'created_at', 'current_humidity' : 'humidity', #rename to match previous data\n",
    "                                  'current_temp_f':'temperature', 'pm2_5_cf_1' : 'pm2.5_cf_1_a', 'pm2_5_cf_1_b':'pm2.5_cf_1_b'})\n",
    "        df['created_at'] =  pd.to_datetime(df['created_at'], format=\"%Y/%m/%dT%H:%M:%Sz\")\n",
    "        start_date = google['Start'][google['Sensor ID to Pull'] == senslist[i]].iloc[0] #store the start date of measurements\n",
    "        df = df[df['created_at'].dt.strftime('%Y/%m/%d') >= start_date] # only keep data after \"start_date\" of measurements\n",
    "        df['humidity'] = df['humidity'].astype('float')\n",
    "        df['temperature'] = df['temperature'].astype('float')\n",
    "        ten = df.groupby(pd.Grouper(key=\"created_at\", freq=\"10min\")).mean(numeric_only = True).reset_index() #take 10-min averages of the data\n",
    "        SD_df = pd.concat([SD_df, ten4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd11021",
   "metadata": {},
   "source": [
    "### Combining the online and SD card data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2d1dd667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If the following values are not zero, something is wrong\n",
      "online pull:  0 SD card:  0\n",
      "online pull:  0 SD card:  0\n",
      "online pull:  0 SD card:  0\n"
     ]
    }
   ],
   "source": [
    "combined_SD_online = pd.DataFrame()\n",
    "print('If the following values are not zero, something is wrong.')\n",
    "for i in range(len(senslist)):\n",
    "    online_onesensor = online_df[online_df['ID'] == strsenslist2[i]]\n",
    "    SD_onesensor = SD_df[SD_df['ID'] == strsenslist2[i]]\n",
    "    if (len(online_onesensor) > 0) & (len(SD_onesensor) > 0):\n",
    "            combined_df = pd.concat([SD_onesensor[['created_at', 'humidity', 'temperature', 'pm2.5_cf_1_a', 'pm2.5_cf_1_b']], \n",
    "                                     online_onesensor[['created_at', 'humidity', 'temperature', 'pm2.5_cf_1_a', 'pm2.5_cf_1_b']]]).drop_duplicates(subset='created_at', keep= 'first')\n",
    "            combined_df['ID'] = senslist2[i]\n",
    "            combined_SD_online = pd.concat([combined_SD_online, combined_df])\n",
    "    elif (len(online_onesensor) > 0) & (len(SD_onesensor) == 0):\n",
    "            online_onesensor['ID'] = senslist2[i]\n",
    "            combined_SD_online = pd.concat([combined_SD_online, online_onesensor])\n",
    "    elif (len(online_onesensor) == 0) & (len(SD_onesensor) > 0):\n",
    "            SD_onesensor['ID'] = senslist2[i]\n",
    "            combined_SD_online = pd.concat([combined_SD_online, combined_df])\n",
    "    else: # These should only ever be 0! otherwise it should be saved in the other categories\n",
    "        print('online pull: ', len(online_onesensor), \n",
    "              'SD card: ', len(SD_onesensor))\n",
    "combined_SD_online.to_csv('../data/raw_combinedSDonline.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8a1163",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
